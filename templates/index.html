<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Singing-Triggered Chord Progression</title>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/socket.io/4.0.1/socket.io.js"></script>
    <script src="https://unpkg.com/soundfont-player@latest/dist/soundfont-player.min.js"></script>
</head>
<body>
    <h1>Singing-Triggered Chord Progression</h1>
    <p>This app listens to your singing and generates chord progressions in real-time.</p>
    <p>Start by clicking "Start Listening" and begin singing after 5 seconds.</p>
    <p>The app will detect your key and play chords to accompany you.</p>
    <p>Currently the app uses a tempo of 120 bpm and plays a metronome when it starts.</p>
    <button id="startButton">Start Listening</button>
    <button id="stopButton">Stop</button>
    <div id="status">Ready to start</div>
    <div id="debugInfo"></div>

    <script>
        const socket = io();
        const startButton = document.getElementById('startButton');
        const stopButton = document.getElementById('stopButton');
        const statusDiv = document.getElementById('status');
        const debugInfoDiv = document.getElementById('debugInfo');

        let audioContext, analyser, microphone, javascriptNode;
        let isListening = false;
        let pianoInstrument;
        let listeningState = 'OFF';
        let tempo = 120, key;
        let chordTimeout;
        let metronomeInterval;

        const notes = ['C', 'C#', 'D', 'D#', 'E', 'F', 'F#', 'G', 'G#', 'A', 'A#', 'B'];

        // Audio detection parameters
        const DETECTION_THRESHOLD = 10;
        const DETECTION_SMOOTHING = 0.8;
        let smoothedVolume = 0;
        let singingStartTime = 0;
        let silenceStartTime = 0;
        let audioBuffer = [];
        let isFirstFiveSeconds = true;

        startButton.onclick = startListening;
        stopButton.onclick = stopEverything;

        socket.on('connect', () => {
            console.log('Connected to server');
        });

        socket.on('listening_started', (data) => {
            tempo = data.tempo;
            key = data.key;
            console.log(`Listening started. Initial Tempo: ${tempo}, Key: ${key}`);
            startMetronome();
        });

        socket.on('detection_result', (data) => {
            tempo = data.tempo;
            key = data.key;
            console.log(`Detected BPM: ${tempo}, Key: ${key}`);
            statusDiv.textContent = `Detected BPM: ${tempo}, Key: ${key}`;
            isFirstFiveSeconds = false;
            startMetronome(); // Restart metronome with new tempo
        });

        socket.on('chord', (data) => {
            console.log('Received chord:', data);
            playChord(data.chord, data.key);
        });

        async function startListening() {
            if (isListening) return;

            try {
                audioContext = new (window.AudioContext || window.webkitAudioContext)();
                await audioContext.resume();
                console.log("AudioContext initialized and resumed");

                const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                microphone = audioContext.createMediaStreamSource(stream);
                analyser = audioContext.createAnalyser();
                analyser.fftSize = 2048;
                javascriptNode = audioContext.createScriptProcessor(2048, 1, 1);

                microphone.connect(analyser);
                analyser.connect(javascriptNode);
                javascriptNode.connect(audioContext.destination);

                javascriptNode.onaudioprocess = detectAudio;

                pianoInstrument = await Soundfont.instrument(audioContext, 'acoustic_grand_piano');
                console.log("Piano instrument loaded successfully:", pianoInstrument);

                isListening = true;
                statusDiv.textContent = "Listening for singing...";
                socket.emit('start_listening');
                console.log('Listening started');
                startMetronome();
            } catch (error) {
                console.error('Error starting audio:', error);
                statusDiv.textContent = "Error starting audio. Please try again.";
            }
        }

        function startMetronome() {
            if (metronomeInterval) clearInterval(metronomeInterval);
            playMetronomeClick();
            metronomeInterval = setInterval(playMetronomeClick, (60 / tempo) * 1000);
        }

        function playMetronomeClick() {
            const clickOscillator = audioContext.createOscillator();
            const clickGain = audioContext.createGain();

            clickOscillator.connect(clickGain);
            clickGain.connect(audioContext.destination);

            clickOscillator.frequency.value = 1000; // 1000 Hz "click" sound
            clickGain.gain.setValueAtTime(0, audioContext.currentTime);
            clickGain.gain.linearRampToValueAtTime(0.3, audioContext.currentTime + 0.001);
            clickGain.gain.linearRampToValueAtTime(0, audioContext.currentTime + 0.001 + 0.1);

            clickOscillator.start();
            clickOscillator.stop(audioContext.currentTime + 0.1);
        }

        function detectAudio(event) {
            const array = new Uint8Array(analyser.frequencyBinCount);
            analyser.getByteFrequencyData(array);
            const average = array.reduce((a, b) => a + b) / array.length;

            smoothedVolume = DETECTION_SMOOTHING * smoothedVolume + (1 - DETECTION_SMOOTHING) * average;

            const now = Date.now();
            if (smoothedVolume > DETECTION_THRESHOLD) {
                if (singingStartTime === 0) {
                    singingStartTime = now;
                    audioBuffer = [];
                    isFirstFiveSeconds = true;
                }
                silenceStartTime = 0;

                // Collect audio data for the first 5 seconds
                if (isFirstFiveSeconds && audioBuffer.length < 5 * audioContext.sampleRate) {
                    audioBuffer = audioBuffer.concat(Array.from(event.inputBuffer.getChannelData(0)));
                    if (audioBuffer.length >= 5 * audioContext.sampleRate) {
                        socket.emit('audio_data', { audio: new Float32Array(audioBuffer).buffer });
                    }
                }

                if (now - singingStartTime > 5000 && listeningState === 'OFF') {
                    listeningState = 'ON';
                    statusDiv.textContent = "Singing detected. Playing chords.";
                    startChordProgression();
                }
            } else {
                if (silenceStartTime === 0) {
                    silenceStartTime = now;
                }
                singingStartTime = 0;

                if (now - silenceStartTime > 5000 && listeningState === 'ON') {
                    listeningState = 'OFF';
                    statusDiv.textContent = "Silence detected. Stopped playing chords.";
                    stopChordProgression();
                }
            }

            debugInfoDiv.textContent = `Volume: ${smoothedVolume.toFixed(2)}, State: ${listeningState}, Singing Time: ${singingStartTime ? now - singingStartTime : 0}ms, Silence Time: ${silenceStartTime ? now - silenceStartTime : 0}ms`;
        }

        function startChordProgression() {
            requestNextChord();
        }

        function requestNextChord() {
            if (listeningState === 'ON') {
                socket.emit('request_chord', { melody_note: 'C' });  // Default to C as we're not detecting pitch
                chordTimeout = setTimeout(requestNextChord, (60 / tempo) * 1000);
            }
        }

        function stopChordProgression() {
            clearTimeout(chordTimeout);
        }

        function playChord(chord, key) {
            console.log(`Playing chord: ${chord} in key ${key}`);
            const notes = getChordNotes(chord, key);
            const currentTime = audioContext.currentTime;
            const duration = 60 / tempo;
            notes.forEach(note => {
                pianoInstrument.play(note, currentTime, { duration: duration, gain: 0.5 });
            });
        }

        function getChordNotes(chord, key) {
            const romanToSemitones = {'I': 0, 'II': 2, 'III': 4, 'IV': 5, 'V': 7, 'VI': 9, 'VII': 11};
            const keyIndex = notes.indexOf(key);
            const chordIndex = (keyIndex + romanToSemitones[chord.toUpperCase()]) % 12;
            const rootNote = notes[chordIndex];
            const isMinor = chord.toLowerCase() === chord;
            const thirdIndex = (chordIndex + (isMinor ? 3 : 4)) % 12;
            const fifthIndex = (chordIndex + 7) % 12;

            return [
                notes[chordIndex] + '4',
                notes[thirdIndex] + '4',
                notes[fifthIndex] + '4'
            ];
        }

        function stopEverything() {
            console.log('Stopping everything');
            if (audioContext) {
                if (javascriptNode) javascriptNode.onaudioprocess = null;
                if (microphone) microphone.disconnect();
                if (analyser) analyser.disconnect();
                if (metronomeInterval) {
                    clearInterval(metronomeInterval);
                    metronomeInterval = null;
                }
                audioContext.close().then(() => {
                    audioContext = null;
                    pianoInstrument = null;
                    isListening = false;
                    listeningState = 'OFF';
                    singingStartTime = 0;
                    silenceStartTime = 0;
                    clearTimeout(chordTimeout);
                    statusDiv.textContent = "Stopped. Click 'Start Listening' to begin again.";
                    console.log('Audio stopped and microphone disconnected');
                });
            }
        }
    </script>
</body>
</html>
